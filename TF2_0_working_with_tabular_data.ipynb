{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2.0_working_with_tabular_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg8r9FzP__xk"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1p1VrpeaNa8tCuRjZXZAueUEupP5RvKm3?usp=sharing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWfWFm2edyMG"
      },
      "source": [
        "# Working with tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lDPHYy1jDVe"
      },
      "source": [
        "## Titanic dataset download and overview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4TSFfeDEUhs"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers.experimental import preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H4zLwvSR0PX"
      },
      "source": [
        "pd.set_option('max_rows', 10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBRqQw_sV2YD"
      },
      "source": [
        "### Overview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26BrsMaPEbdQ"
      },
      "source": [
        "TRAIN_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n",
        "TEST_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W8FbkLNEw8-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgg7nIVQ9Qxc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y9QB00VjsZT"
      },
      "source": [
        "## Data preparation and exploratory analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV1kd4abU9pG"
      },
      "source": [
        "### Split the dataframe into train, validation and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f3jFE4J9U7t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5U2VLcU9UqR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6vO7WT09Um9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlmYgG26enYS"
      },
      "source": [
        "### Exploratory analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ7GBn8N9icq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZPLQYU99iaN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuBKqDep9iXq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qny1jxBFpFwH"
      },
      "source": [
        "## Feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twXBSxnT66o8"
      },
      "source": [
        "### Numeric columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlsaY02wRSZ6"
      },
      "source": [
        "train.describe()\n",
        "# You can see that the min values for most of the numeric fields are close to 0.\n",
        "# The maximum values vary a fair bit where we have 512 for the fair paid but maximum number for the number of siblings and spouses is only 8. \n",
        "# That's quite a big difference which is why we apply normalization."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OosUh4kTsK_q"
      },
      "source": [
        "`get_normalization_layer` function returns a layer which applies featurewise normalization to numerical features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6OuEKMMyEq1"
      },
      "source": [
        "def get_normalization_layer(name, dataset):\n",
        "  normalizer = preprocessing.Normalization(axis=None)\n",
        "  feature_ds = dataset.map(lambda x, y: x[name])\n",
        "  normalizer.adapt(feature_ds)\n",
        "\n",
        "  return normalizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tPWogCHa7bf"
      },
      "source": [
        "age_column = train_features['age']\n",
        "age_column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H0fzmP6bUPb"
      },
      "source": [
        "numeric_layer = get_normalization_layer('age', train_ds)\n",
        "numeric_layer(age_column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVD--2WZ7vmh"
      },
      "source": [
        "### Categorical columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x49mT8vyfKNB"
      },
      "source": [
        "In this dataset, the town that passengers embarked is represented as a string (e.g. 'Southampton', 'Cherbourg', 'Queenstown' or 'unknown'). You cannot feed strings directly to a model. The preprocessing layer takes care of representing strings as a one-hot vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqmBUXgneEF1"
      },
      "source": [
        "train.embark_town.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmgaeRjlDoUO"
      },
      "source": [
        "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
        "  # Create a StringLookup layer which will turn strings into integer indices\n",
        "  if dtype == 'string':\n",
        "    index = preprocessing.StringLookup(max_tokens=max_tokens)\n",
        "  else:\n",
        "    index = preprocessing.IntegerLookup(max_tokens=max_tokens)\n",
        "\n",
        "  # Prepare a Dataset that only yields our feature\n",
        "  feature_ds = dataset.map(lambda x, y: x[name])\n",
        "\n",
        "  # Learn the set of possible values and assign them a fixed integer index.\n",
        "  index.adapt(feature_ds)\n",
        "\n",
        "  # Create a Discretization for our integer indices.\n",
        "  encoder = preprocessing.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
        "\n",
        "  # Apply one-hot encoding to our indices. The lambda function captures the\n",
        "  # layer so we can use them, or include them in the functional model later.\n",
        "  return lambda feature: encoder(index(feature))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPdk6WMHfv1v"
      },
      "source": [
        "embark_town_column = train_features['embark_town']\n",
        "embark_town_column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2t2ff9K8PcT"
      },
      "source": [
        "categorical_layer = get_category_encoding_layer('embark_town', train_ds, 'string')\n",
        "categorical_layer(embark_town_column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8LMv-6tjB53"
      },
      "source": [
        "### Creating a pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wVwChZii8Sz"
      },
      "source": [
        "batch_size = 64\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tjh_MrwtjP4x"
      },
      "source": [
        "all_inputs = []\n",
        "encoded_features = []\n",
        "numeric_columns = ['age', 'n_siblings_spouses', 'parch', 'fare']\n",
        "\n",
        "# Numeric features.\n",
        "for header in numeric_columns:\n",
        "  numeric_column = tf.keras.Input(shape=(1,), name=header)\n",
        "  normalization_layer = get_normalization_layer(header, train_ds)\n",
        "  encoded_numeric_column = normalization_layer(numeric_column)\n",
        "  all_inputs.append(numeric_column)\n",
        "  encoded_features.append(encoded_numeric_column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54rOtESOksYQ"
      },
      "source": [
        "train.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVJ4WxINjP2E"
      },
      "source": [
        "# Categorical features encoded as string.\n",
        "\n",
        "categorical_columns = ['sex', 'class', 'embark_town', 'deck', 'alone']\n",
        "for header in categorical_columns:\n",
        "  categorical_column = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
        "  encoding_layer = get_category_encoding_layer(header, train_ds, dtype='string', max_tokens=5)\n",
        "  encoded_categorical_column = encoding_layer(categorical_column)\n",
        "  all_inputs.append(categorical_column)\n",
        "  encoded_features.append(encoded_categorical_column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaV4pQ1CnO9-"
      },
      "source": [
        "## Create, compile and train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVh9afkUo890"
      },
      "source": [
        "### Create and compile model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPMAQREf-fmW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RauLatYIpB-O"
      },
      "source": [
        "### Train and evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCIjRiHI-mJ1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhPvBSuq-l90"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X47jaxRmpgd-"
      },
      "source": [
        "### Inference on new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZpFhxD4T2zv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}